#define QUALITY	1	// Set to 0 for performance, 1 for quality
#define DITHER	1	// Set to 1 to use a dither pattern

uniform sampler2DRect texDepth;	// Depth texture
uniform sampler2DRect texNormal;// Normal texture

#if DITHER
uniform sampler2D texDither;	// Random normal texture to create a dither pattern
#endif

uniform vec3 ranSphere[32];		// Random points inside an unit sphere

// We cannot use gl_DepthRange since we are currently rendering the fullscreen quad not the scene
const vec2 camerarange = vec2(1.0, 500.0);
uniform mat4 projection;

varying vec2 texCoord;
varying vec2 viewVector;

uniform int screenWidth;
uniform int screenHeight;
uniform float radius;
const int sample = 32;
float oneOverRadius2;

float convertDepth(in float d)
{
	float nearZ = camerarange.x;
	float farZ = camerarange.y;

	return (2.0 * nearZ) / (nearZ + farZ - d * (farZ - nearZ));
}

float readDepth(in vec2 coord)
{
	float d = texture2DRect(texDepth, coord).x;
	return convertDepth(d);
}

// Get the view-space poisition by the given screen-space pixel position
vec3 clipToView(in vec2 viewVector, in float planDepth)
{
	// The calculation should involve several steps, but the terms get canceled out into
	// a single multiplication, as we setup viewVector.z equals to 1 in vertex shader.
	// vec3 view = normalize(vec3(viewVector, -1));
	// float viewVectorLength = planDepth / -view.z;
	// return view * viewVectorLength;

	return planDepth * vec3(viewVector, 1.0);
}

// Get the clip-space poisition by the given view-space position
vec2 viewToClip(in vec3 ep)
{
	// Using the projection matrix to project from view space to clip space,
	// but we can ignore the zero terms and the final z component.
	// Original code:
	// vec4 p = projection * vec4(ep, 1);
	// return p.xy / -p.w;

	ep.xy *= vec2(projection[0][0], projection[1][1]);
	return ep.xy / -ep.z * projection[2][3];
}

// Clip to screen space transform
vec3 clipToScreen(in vec2 clipPos)
{
	vec2 screenXY = clipPos.xy * 0.5 + 0.5;
	screenXY *= vec2(screenWidth, screenHeight);
	return vec3(screenXY, readDepth(screenXY));
}

float calAO(in vec3 origin, in vec3 samplePoint, in float sampleDepth)
{
	if(samplePoint.z < sampleDepth)
		return 0.0;

#if QUALITY
	vec3 diff = vec3(samplePoint.xy, sampleDepth) - origin;
	float distance2 = dot(diff, diff);
#else
	float distance2 = sampleDepth - origin.z;
	distance2 *= distance2;
#endif

	return 1 - min(distance2 * oneOverRadius2, 1.0);
}

void main(void)
{
	// We can use less sample if dithering is enabled
#if DITHER
	const int N = sample;// / 2;
#else
	const int N = sample;
#endif

	oneOverRadius2 = 1.0 / (radius * radius);
	float depth = readDepth(texCoord);

	vec3 ep = clipToView(viewVector, depth);
	vec3 n = texture2DRect(texNormal, texCoord).xyz * 2.0 - 1.0;
	n.z = -n.z;

	float ao = 0.0;

	for(int i=0; i<N; ++i)
	{
		vec3 ranSample = ranSphere[i];

#if DITHER
		ranSample = reflect(ranSample, texture2D(texDither, texCoord / 128.0).xyz);
#endif

		vec3 orientedranSphere = dot(ranSample, n) >= 0.0 ? ranSample : -ranSample;

#if QUALITY
		orientedranSphere += 0.05 * n;	// Bias towards the normal, to reduce self occlusion
#endif

		vec3 ep2 = ep + radius * orientedranSphere;

		// Project the point back to screen-space, with depth value.
		vec3 sp2 = clipToScreen(viewToClip(ep2));

		ao += calAO(ep, ep2, sp2.z);
	}

	ao /= float(N);
	ao *= 2.5;

	gl_FragColor = vec4(1.0 - ao);
}
